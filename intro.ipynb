{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.30-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.38 (from langchain)\n",
      "  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain)\n",
      "  Using cached langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.58-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "     ---------------------------------------- 0.0/107.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 107.3/107.3 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.3-cp312-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.9/50.9 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.18.2-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.6.1 (from pydantic<3,>=1->langchain)\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n",
      "   ---------------------------------------- 0.0/369.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 369.0/369.0 kB 7.6 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Using cached langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "Using cached langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Using cached langsmith-0.1.58-py3-none-any.whl (121 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.7/15.5 MB 14.9 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 2.1/15.5 MB 22.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.5/15.5 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 5.0/15.5 MB 26.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.4/15.5 MB 27.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.8/15.5 MB 27.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.3/15.5 MB 28.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.0/15.5 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.4/15.5 MB 29.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 27.3 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 409.3/409.3 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.18.2-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.2/1.9 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 24.4 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp312-cp312-win_amd64.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.7/138.7 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.6/62.6 kB ? eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.30-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.9/2.1 MB 27.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.1 MB 25.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 26.2 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB ? eta 0:00:00\n",
      "Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "   ---------------------------------------- 0.0/163.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 163.8/163.8 kB 9.6 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.4/100.4 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB ? eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl (293 kB)\n",
      "   ---------------------------------------- 0.0/293.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 293.6/293.6 kB 18.9 MB/s eta 0:00:00\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.8/66.8 kB ? eta 0:00:00\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Downloading orjson-3.10.3-cp312-none-win_amd64.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.8/138.8 kB ? eta 0:00:00\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 121.1/121.1 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.4/76.4 kB ? eta 0:00:00\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tenacity, PyYAML, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, idna, greenlet, frozenlist, charset-normalizer, certifi, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, pydantic-core, marshmallow, jsonpatch, aiosignal, pydantic, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.6.0 attrs-23.2.0 certifi-2024.2.2 charset-normalizer-3.3.2 dataclasses-json-0.6.6 frozenlist-1.4.1 greenlet-3.0.3 idna-3.7 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.1 langsmith-0.1.58 marshmallow-3.21.2 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.3 packaging-23.2 pydantic-2.7.1 pydantic-core-2.18.2 requests-2.31.0 tenacity-8.3.0 typing-extensions-4.11.0 typing-inspect-0.9.0 urllib3-2.2.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.30.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.7.1)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\navee\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.30.1-py3-none-any.whl (320 kB)\n",
      "Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.6/85.6 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 2.2 MB/s eta 0:00:00\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: tqdm, sniffio, h11, distro, httpcore, anyio, httpx, openai\n",
      "Successfully installed anyio-4.3.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.1 sniffio-1.3.1 tqdm-4.66.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n",
    "\n",
    "os.environ['SERPAPI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.8)#,max_tokens=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is openbanking give answer in 3 lines, and give few companies related to openbanking in UK\n",
      "Open banking is a system that allows customers to securely share their financial data with third-party providers through APIs. This enables the use of innovative financial services such as budgeting tools and loan comparisons.\n",
      "\n",
      "Some companies related to open banking in the UK are Monzo, Revolut, and Starling Bank. These companies offer online banking services and make use of open banking to provide their customers with a more personalized and efficient banking experience. Other examples include Yolt, Cleo, and Moneybox.\n"
     ]
    }
   ],
   "source": [
    "question = \"what is openbanking give answer in 3 lines, and give few companies related to openbanking in UK\"\n",
    "\n",
    "answer = llm.invoke(question).strip()\n",
    "\n",
    "print(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo',temperature=0.85, max_tokens=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please gvie recepie of chicken butter masala step wise process\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    #input_variables=['dish'],\n",
    "    template= \"please gvie recepie of {dish} step wise process\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(dish = 'chicken butter masala')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please gvie recepie of chicken butter masala step wise process\n",
      "Ingredients:\n",
      "- 500 grams boneless chicken, cut into bite-sized pieces\n",
      "- 1 large onion, chopped\n",
      "- 2 tablespoons butter\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 teaspoon cumin seeds\n",
      "- 1 teaspoon ginger paste\n",
      "- 1 teaspoon garlic paste\n",
      "- 1 teaspoon turmeric powder\n",
      "- 1 teaspoon red chili powder\n",
      "- 1 teaspoon coriander powder\n",
      "- 1 teaspoon garam masala powder\n",
      "- 1 cup tomato puree\n",
      "- 1/2 cup heavy cream\n",
      "- Salt to taste\n",
      "- Fresh coriander leaves for garnishing\n",
      "\n",
      "Step-by-Step Recipe:\n",
      "\n",
      "1. In a pan, heat 2 tablespoons of butter and 2 tablespoons of vegetable oil on medium heat.\n",
      "\n",
      "2. Add 1 teaspoon of cumin seeds and let them splutter for a few seconds.\n",
      "\n",
      "3. Then add the chopped onion and sauté until it turns golden brown.\n",
      "\n",
      "4. Add 1 teaspoon of ginger paste and 1 teaspoon of garlic paste and sauté for a minute.\n",
      "\n",
      "5. Add the boneless chicken pieces and cook until they are lightly browned.\n",
      "\n",
      "6. Now add 1 teaspoon of turmeric powder, 1 teaspoon of red chili powder, 1 teaspoon of coriander powder, and 1 teaspoon of garam masala powder. Mix well and cook for a minute.\n",
      "\n",
      "7. Add 1 cup of tomato puree and mix everything together.\n",
      "\n",
      "8. Cover the pan and let the chicken cook for 10-15 minutes on medium heat.\n",
      "\n",
      "9. Once the chicken is cooked, add 1/2 cup of heavy cream and mix well.\n",
      "\n",
      "10. Adjust the salt according to taste and let the chicken simmer for another 5 minutes.\n",
      "\n",
      "11. Garnish with fresh coriander leaves and serve hot with rice or naan bread. Enjoy your delicious chicken butter masala!\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke(prompt).strip()\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: please gvie recepie of butter chicken masala step wise process\n",
      "recipe for butter chicken masala:\n",
      "Ingredients:\n",
      "- 500g boneless chicken, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tbsp ginger garlic paste\n",
      "- 1 tsp red chili powder\n",
      "- 1 tsp cumin powder\n",
      "- 1 tsp coriander powder\n",
      "- 1 tsp garam masala powder\n",
      "- 1 tsp turmeric powder\n",
      "- Salt to taste\n",
      "- 2 tbsp butter\n",
      "- 1 onion, finely chopped\n",
      "- 1 tsp cumin seeds\n",
      "- 1 tbsp tomato paste\n",
      "- 1 cup crushed tomatoes\n",
      "- 1 cup chicken broth\n",
      "- 1/4 cup heavy cream\n",
      "- Fresh coriander for garnish\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. In a large bowl, mix together the chicken, yogurt, ginger garlic paste, red chili powder, cumin powder, coriander powder, garam masala powder, turmeric powder, and salt. Make sure the chicken pieces are evenly coated with the marinade. Cover the bowl and let it marinate in the fridge for at least 30 minutes or up to 2 hours.\n",
      "\n",
      "2. In a large pan, heat the butter over medium heat. Add the chopped onion and cumin seeds. Saute for 2-3 minutes until the onion is translucent.\n",
      "\n",
      "3. Add the marinated chicken to the pan and cook for 5-7 minutes until it starts to brown.\n",
      "\n",
      "4. Stir in the tomato paste and cook for another 2-3 minutes.\n",
      "\n",
      "5. Add the crushed tomatoes and chicken broth to the pan. Bring it to a boil, then reduce the heat to low and let it simmer for 15-20 minutes, stirring occasionally.\n",
      "\n",
      "6. Once the chicken is cooked through, add the heavy cream and stir well. Let it simmer for another 2-3 minutes.\n",
      "\n",
      "7. Garnish with fresh coriander and serve hot with naan or rice.\n",
      "\n",
      "Enjoy your delicious butter chicken masala!\n",
      "\n",
      "prompt: please gvie recepie of gulab jamun step wise process\n",
      "recipe for gulab jamun:\n",
      "Ingredients:\n",
      "- 1 cup all-purpose flour\n",
      "- 1/4 cup milk powder\n",
      "- 1/4 tsp baking powder\n",
      "- Pinch of salt\n",
      "- 2 tbsp ghee or melted butter\n",
      "- 1/3 cup milk (approximately)\n",
      "- Oil for deep frying\n",
      "- 1 1/2 cups sugar\n",
      "- 1 cup water\n",
      "- 1 tsp cardamom powder\n",
      "- 1 tbsp rose water (optional)\n",
      "- Chopped nuts for garnish (optional)\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. In a mixing bowl, combine the all-purpose flour, milk powder, baking powder, and salt. Give it a quick mix.\n",
      "\n",
      "2. Add the ghee or melted butter to the dry ingredients and mix well. Using your fingers, rub the ghee into the flour mixture until it resembles coarse crumbs.\n",
      "\n",
      "3. Gradually add the milk, a little at a time, and mix until a soft and smooth dough forms. The dough should not be too dry or too sticky.\n",
      "\n",
      "4. Cover the dough with a damp cloth and let it rest for 15-20 minutes.\n",
      "\n",
      "5. In the meantime, prepare the sugar syrup by combining sugar and water in a deep pan. Bring it to a boil and let it simmer for 5-7 minutes until the syrup thickens slightly. Add cardamom powder and rose water (if using) and turn off the heat.\n",
      "\n",
      "6. Heat oil in a deep pan for frying the gulab jamuns. Make sure the oil is not too hot, otherwise, the gulab jamuns will cook on the outside but remain raw on the inside.\n",
      "\n",
      "7. Divide the dough into small balls and roll them between your palms until smooth. Make sure there are no cracks on the surface. If the dough feels dry, add a little milk and knead again.\n",
      "\n",
      "8. Gently drop the gulab jamuns into the hot oil and fry them on low-medium heat until they turn golden brown. Make sure to fry them slowly to ensure they cook evenly from the inside.\n",
      "\n",
      "9. Once done, remove the gulab jamuns from the oil and drain them on a paper towel to remove excess oil.\n",
      "\n",
      "10. Immediately add the fried gulab jamuns to the warm sugar syrup and let them soak for at least 1 hour.\n",
      "\n",
      "11. Garnish with chopped nuts, if desired, and serve hot or at room temperature.\n",
      "\n",
      "Your delicious gulab jamuns are ready to be enjoyed! Serve them as a\n",
      "\n",
      "prompt: please gvie recepie of indian naan roti step wise process\n",
      "recipe for indian naan roti:\n",
      "Ingredients:\n",
      "- 2 cups all-purpose flour\n",
      "- 1 tsp baking powder\n",
      "- 1/2 tsp baking soda\n",
      "- 1/2 tsp salt\n",
      "- 1/4 cup plain yogurt\n",
      "- 1/4 cup warm water\n",
      "- 1 tbsp vegetable oil\n",
      "- Extra flour for dusting\n",
      "- Melted butter or ghee for brushing\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. In a large mixing bowl, combine the flour, baking powder, baking soda, and salt.\n",
      "2. Add in the yogurt, warm water, and vegetable oil. Mix well until a dough forms.\n",
      "3. Knead the dough on a floured surface for about 5 minutes, until it becomes smooth and elastic.\n",
      "4. Place the dough back in the mixing bowl and cover it with a damp cloth. Let it rest for 1 hour.\n",
      "5. Preheat a cast iron skillet or non-stick pan on medium heat for about 5 minutes.\n",
      "6. Divide the dough into 8 equal portions and roll each one out into an oval shape, about 1/4 inch thick.\n",
      "7. Dust the flattened dough with flour and place it on the hot skillet.\n",
      "8. Cook for about 1 minute, until bubbles start to form on the surface.\n",
      "9. Flip the naan and cook for another minute on the other side.\n",
      "10. Remove from the skillet and brush with melted butter or ghee.\n",
      "11. Repeat with the remaining dough portions.\n",
      "12. Serve hot with your favorite Indian curry or dish. Enjoy!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dishes = ['butter chicken masala', 'gulab jamun', 'indian naan roti']\n",
    "\n",
    "for dish in dishes:\n",
    "    prompt = prompt_template.format(dish=dish)\n",
    "    print(f\"prompt: {prompt}\")\n",
    "    output =llm.invoke(prompt).strip()\n",
    "    print(f\"recipe for {dish}:\\n{output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"what is top 3 compines that make {product}, just give company name in list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product name 'car tyres'\n",
      "1. Bridgestone Corporation\n",
      "2. Michelin\n",
      "3. Goodyear Tire & Rubber Company\n",
      "\n",
      "product name 'mobile phones'\n",
      "1. Samsung\n",
      "2. Apple\n",
      "3. Huawei\n",
      "\n",
      "product name 'motor bikes'\n",
      "1. Honda\n",
      "2. Yamaha\n",
      "3. Harley-Davidson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "\n",
    "products = [\"car tyres\",\"mobile phones\", \"motor bikes\"]\n",
    "\n",
    "for product in products:\n",
    "    \n",
    "    output=chain.run(product).strip()\n",
    "    print(f\"product name '{product}'\")\n",
    "    print(f\"{output}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate.from_template(\"what is top 3 compines that make {product}, just give company name in list\")\n",
    "chain1 = LLMChain(llm=llm,prompt=prompt1)\n",
    "\n",
    "prompt2 = PromptTemplate.from_template(\"why this {companies} you feel top and best, and give format like 'company name : why is top and best'\")\n",
    "chain2 = LLMChain(llm=llm,prompt=prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [chain1,chain2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Goodyear: Goodyear has been a trusted and well-respected tire company for over 120 years. They have a long history of producing high-quality tires that are known for their durability, reliability, and performance. Goodyear also has a strong presence in the racing industry, with their tires being used in top racing events such as NASCAR and Formula One. They also have a wide range of tire options to suit different vehicles and driving needs, making them a top choice for many drivers.\n",
      "\n",
      "2. Michelin: Michelin is another well-known and highly regarded tire company, with a reputation for producing top-quality tires. They are known for their innovative tire designs and technology, such as the use of their patented EverGrip technology which improves grip and traction on wet roads. Michelin also has a strong commitment to sustainability and has been recognized for their efforts in reducing their environmental impact. This dedication to innovation and sustainability sets them apart and makes them a top choice for many consumers.\n",
      "\n",
      "3. Bridgestone: Bridgestone is one of the largest tire companies in the world and has a presence in over 150 countries. They are known for their high-performance tires, particularly in the sports car and racing industries. Bridgestone has a strong focus on\n"
     ]
    }
   ],
   "source": [
    "respose=chain.run(\"car tyres\").strip()\n",
    "\n",
    "print(respose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product name 'car tyres'\n",
      "1. Bridgestone: Bridgestone is considered top and best because of its reputation for producing high-quality tires with superior performance. They have a wide range of products that cater to different types of vehicles and driving conditions, making them a reliable choice for consumers. Additionally, Bridgestone invests heavily in research and development to constantly improve their products, ensuring that they stay ahead of the competition.\n",
      "\n",
      "2. Michelin: Michelin is known for its innovative technology and exceptional quality, which has made it a top choice among drivers. Their tires are designed to provide excellent grip, durability, and fuel efficiency, making them a popular option for both everyday use and high-performance vehicles. Michelin also has a strong focus on sustainability, using eco-friendly materials in their production process and offering tire recycling programs for their customers.\n",
      "\n",
      "3. Goodyear: Goodyear has a long history of producing reliable and long-lasting tires, which has earned them a top spot in the industry. They provide a wide range of products for different vehicles and driving needs, including tires for commercial trucks and aviation. Goodyear is also known for its cutting-edge technology and innovations, such as their RunOnFlat tires that allow drivers to continue driving even after a puncture.\n",
      "\n",
      "product name 'mobile phones'\n",
      "Apple: Apple is considered top and best due to its strong brand reputation, innovative products, and loyal customer base. They are consistently at the forefront of technology, setting trends and pushing boundaries with their design and features. They also have a strong focus on user experience and customer satisfaction.\n",
      "\n",
      "Samsung: Samsung has a strong presence in the global market and is known for its high-quality products with a wide range of options. They offer a variety of products from smartphones to home appliances, making them a top choice for many consumers. They also have a strong focus on innovation and regularly introduce new features and technologies in their products.\n",
      "\n",
      "Huawei: Huawei has become a top and best choice for many due to its affordable prices and high-quality products. They have a strong presence in the smartphone market and offer a wide range of options to cater to different needs and budgets. They are also known for their advanced technology and reliable performance, making them a top choice for many consumers.\n",
      "\n",
      "product name 'motor bikes'\n",
      "1. Honda: Honda has been a top player in the motorcycle industry for decades, consistently producing high-quality and reliable motorcycles. They have a wide range of models to cater to different riding styles and needs, from sports bikes to scooters. Moreover, Honda has a strong reputation for innovative technology, making their bikes both powerful and fuel-efficient. \n",
      "\n",
      "2. Yamaha: Yamaha is known for its high-performance motorcycles with advanced technology and sleek designs. They have a strong presence in the racing world, producing championship-winning bikes in MotoGP, Superbike, and Motocross. Yamaha also offers a diverse range of motorcycles, from sporty models to comfortable touring bikes, catering to a wide range of riders. \n",
      "\n",
      "3. Suzuki: Suzuki has a long history in the motorcycle industry and has established itself as a reliable and trustworthy brand. They have a reputation for producing bikes that offer a perfect balance between power and handling, making them a top choice for both beginners and experienced riders. Suzuki also has a strong global presence, with a wide range of models available in different markets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products = [\"car tyres\",\"mobile phones\", \"motor bikes\"]\n",
    "\n",
    "for product in products:\n",
    "    \n",
    "    output=chain.run(product).strip()\n",
    "    print(f\"product name '{product}'\")\n",
    "    print(f\"{output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', \"menu_items\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'indian', 'restaurant_name': '\\n\\n\"Spice Palace\" or \"Taste of India\"', 'menu_items': '\\n1. Chicken Tikka Masala: tender chicken pieces cooked in a creamy tomato-based sauce with a blend of spices\\n2. Vegetable Samosas: crispy pastries filled with potatoes, peas, and spices\\n3. Lamb Vindaloo: tender lamb cooked in a spicy and tangy tomato-based sauce\\n4. Palak Paneer: creamy spinach and cottage cheese curry\\n5. Tandoori Chicken: marinated chicken cooked in a clay oven\\n6. Biryani: fragrant basmati rice cooked with spices, vegetables, and your choice of chicken, lamb, or shrimp\\n7. Butter Chicken: juicy chicken cooked in a rich and buttery tomato-based sauce\\n8. Chana Masala: chickpeas cooked in a flavorful blend of spices and tomato sauce\\n9. Naan: traditional Indian flatbread baked in a clay oven\\n10. Mango Lassi: refreshing yogurt-based drink with mango and spices.'}\n"
     ]
    }
   ],
   "source": [
    "print(chain({\"cuisine\": \"indian\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->google-search-results) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->google-search-results) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->google-search-results) (2024.2.2)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (pyproject.toml): started\n",
      "  Building wheel for google-search-results (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32084 sha256=fdc40c9084240e90420fcf2d303bc0261d7909d7d2a1d9333c14fba833347a0a\n",
      "  Stored in directory: c:\\users\\navee\\appdata\\local\\pip\\cache\\wheels\\0c\\47\\f5\\89b7e770ab2996baf8c910e7353d6391e373075a0ac213519e\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numexpr\n",
      "  Downloading numexpr-2.10.0-cp312-cp312-win_amd64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\navee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from numexpr) (1.26.4)\n",
      "Downloading numexpr-2.10.0-cp312-cp312-win_amd64.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/97.1 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/97.1 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 20.5/97.1 kB 165.2 kB/s eta 0:00:01\n",
      "   ------------ --------------------------- 30.7/97.1 kB 217.9 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 71.7/97.1 kB 357.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 97.1/97.1 kB 396.7 kB/s eta 0:00:00\n",
      "Installing collected packages: numexpr\n",
      "Successfully installed numexpr-2.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\navee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m This seems like a question about a specific technology.\n",
      "Action: Search\n",
      "Action Input: openAI chatgpt 4o\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': \"OpenAI releases GPT-4o, a faster model that's free for all ChatGPT users\", 'link': 'https://www.theverge.com/2024/5/13/24155493/openai-gpt-4o-launching-free-for-all-chatgpt-users', 'source': 'The Verge', 'date': '2 days ago', 'thumbnail': 'https://serpapi.com/searches/6645ea27d737d79c1e8b728a/images/13a51e616d9863715240f49289a45ab9bd193b912a838aef.jpeg'}, {'title': \"With OpenAI's Release of GPT-4o, Is ChatGPT Plus Still Worth It?\", 'link': 'https://www.wired.com/story/with-gpt-4o-is-chatgpt-plus-still-worth-it/', 'source': 'WIRED', 'date': '2 days ago', 'thumbnail': 'https://serpapi.com/searches/6645ea27d737d79c1e8b728a/images/13a51e616d98637149c46f020dae6cba52a9f36db094d2a1.jpeg'}, {'title': \"OpenAI GPT-4o is now rolling out — here's how to get access\", 'link': 'https://www.tomsguide.com/ai/chatgpt/gpt-4o-is-openais-exciting-new-model-heres-how-to-get-access', 'source': \"Tom's Guide\", 'date': '19 hours ago', 'thumbnail': 'https://serpapi.com/searches/6645ea27d737d79c1e8b728a/images/13a51e616d98637199806993b33219b9367ca10e2173cc75.jpeg'}, {'title': 'OpenAI launches new AI model GPT-4o and desktop version of ChatGPT', 'link': 'https://www.cnbc.com/2024/05/13/openai-launches-new-ai-model-and-desktop-version-of-chatgpt.html', 'source': 'CNBC', 'date': '2 days ago', 'thumbnail': 'https://serpapi.com/searches/6645ea27d737d79c1e8b728a/images/13a51e616d9863713a2d6c75eef89ac9ac17d7f6c9f614b1.jpeg'}, {'title': 'OpenAI Unveils New ChatGPT That Listens, Looks and Talks', 'link': 'https://www.nytimes.com/2024/05/13/technology/openai-chatgpt-app.html', 'source': 'The New York Times', 'date': '2 days ago', 'thumbnail': 'https://serpapi.com/searches/6645ea27d737d79c1e8b728a/images/13a51e616d9863710a8403f992cd011398feccca0ec7b515.jpeg'}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m There are multiple articles discussing the release of GPT-4o, so it must be a new and significant technology.\n",
      "Action: Search\n",
      "Action Input: What is GPT-4o?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'OpenAI GPT-4o — breakthrough voice assistant, new vision features and everything you need to know', 'link': 'https://www.tomsguide.com/ai/live/openai-spring-update-event-live-blog', 'source': \"Tom's Guide\", 'date': '21 hours ago', 'thumbnail': 'https://serpapi.com/searches/6645ea2a1d986e33fe6150a9/images/1a9cafa57abc20ca97d90e00df7b232858f33e5a56a515f4.jpeg'}, {'title': 'OpenAI’s new GPT-4o lets people interact using voice or video in the same model', 'link': 'https://www.technologyreview.com/2024/05/13/1092358/openais-new-gpt-4o-model-lets-people-interact-using-voice-or-video-in-the-same-model/', 'source': 'MIT Technology Review', 'date': '2 days ago', 'thumbnail': 'https://serpapi.com/searches/6645ea2a1d986e33fe6150a9/images/1a9cafa57abc20ca5132bc13322eb42f69a09af9366e5262.jpeg'}, {'title': 'Introducing GPT-4o: OpenAI’s new flagship multimodal model now in preview on Azure', 'link': 'https://azure.microsoft.com/en-us/blog/introducing-gpt-4o-openais-new-flagship-multimodal-model-now-in-preview-on-azure/', 'source': 'Microsoft Azure', 'date': '2 days ago', 'thumbnail': 'https://serpapi.com/searches/6645ea2a1d986e33fe6150a9/images/1a9cafa57abc20caba6e66198de396a9b2df674824459be1.png'}, {'title': \"How to access GPT-4o's voice mode? OpenAI CEO Sam Altman explains this\", 'link': 'https://www.hindustantimes.com/world-news/us-news/how-to-access-gpt-4os-voice-mode-openai-ceo-sam-altman-explains-this-101715839831972.html', 'source': 'Hindustan Times', 'date': '4 hours ago', 'thumbnail': 'https://serpapi.com/searches/6645ea2a1d986e33fe6150a9/images/1a9cafa57abc20ca7d66ccec86b9b275ad844468c4d3b7a9.jpeg'}, {'title': \"With OpenAI's Release of GPT-4o, Is ChatGPT Plus Still Worth It?\", 'link': 'https://www.wired.com/story/with-gpt-4o-is-chatgpt-plus-still-worth-it/', 'source': 'WIRED', 'date': '2 days ago', 'thumbnail': 'https://serpapi.com/searches/6645ea2a1d986e33fe6150a9/images/1a9cafa57abc20ca09d6808d69dab91206c66ca35aa17aac.jpeg'}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The first article seems to indicate that GPT-4o is a voice assistant with new vision features, and the second article mentions a voice mode. It must be a versatile AI model that can understand and respond to both voice and visual inputs.\n",
      "Action: Search\n",
      "Action Input: What is GPT-4o used for?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe multimodal capabilities of GPT-4o can support real-time translation from one language to another. Image understanding and vision. The model can analyze images and videos, allowing users to upload visual content that GPT-4o will understand, be able to explain and provide analysis for.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m It seems like GPT-4o has a variety of uses, including translation and image analysis.\n",
      "Action: Search\n",
      "Action Input: What is the difference between GPT-4o and ChatGPT?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mGPT-4o is OpenAI's third major iteration of their popular large multimodal model, GPT-4, which expands on the capabilities of GPT-4 with Vision. The newly released model is able to talk, see, and interact with the user in an integrated and seamless way, more so than previous versions when using the ChatGPT interface.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m GPT-4o is an upgraded version of GPT-4 with added vision capabilities, and it is designed to work seamlessly with the ChatGPT interface.\n",
      "Thought: I now know the final answer.\n",
      "Final Answer: GPT-4o is a new AI model released by OpenAI that has both voice and vision capabilities, allowing it to understand and respond to both voice and visual inputs. It is an upgraded version of their previous model, GPT-4, and is designed to work seamlessly with the ChatGPT interface.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GPT-4o is a new AI model released by OpenAI that has both voice and vision capabilities, allowing it to understand and respond to both voice and visual inputs. It is an upgraded version of their previous model, GPT-4, and is designed to work seamlessly with the ChatGPT interface.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True,max_iterations=1)\n",
    "\n",
    "agent.run(\"what is openAI chatgpt 4o?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the search tool to find the information about moneyhub UK.\n",
      "Action: Search\n",
      "Action Input: \"operation in moneyhub UK\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Moneyhub is a data and payments fintech that provides open banking, open finance, and open data solutions.', '... UK, Europe, Japan, Australia, Canada and Brazil. ... Focused on the design, proposition, delivery & operation of digital payment solutions across a range of ...', 'Moneyhub, is the leading data and payments platform built on Open Banking and Open Finance principles. Its solutions already help businesses in various sectors ...', \"Want a breakdown of the main aspects of Moneyhub? Here's a few of the features that you'll find in the app to help you on your financial journey.\", 'Moneyhub drives digital engagement and customer loyalty through intelligent personal analytics and financial management solutions.', 'We review Moneyhub – a money management app that helps you budget better by showing you all your accounts in one place.', 'Reference no. 809360 at fca.org.uk/register. Moneyhub Financial Technology Limited is registered in England and Wales with company number 06909772. Registered ...', \"Moneyhub's AI-Powered, Always-On Decisioning and Messaging Platform is already revolutionising the way many financial institutions, including ...\", \"UK-based Moneyhub has been accepted as a supplier on Crown Commercial Service's new Open Banking Dynamic Purchasing System.\", 'If the firm becomes insolvent, you should contact the liquidator or administrator of the firm, who will be responsible for distributing any funds to customers.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Moneyhub is a data and payments fintech that provides open banking, open finance, and open data solutions.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Moneyhub is a data and payments fintech that provides open banking, open finance, and open data solutions.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True,max_iterations=3)\n",
    "\n",
    "agent.run(\"what is operation in moneyhub Uk, get maximum inforamtion in single search \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product name 'genrative AI'\n",
      "1. OpenAI\n",
      "2. Google DeepMind\n",
      "3. IBM Watson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory=ConversationBufferMemory()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"what is top 3 compines that make {product}, just give company name in list\")\n",
    "\n",
    "chain = LLMChain(llm=llm,prompt=prompt,memory=memory)\n",
    "\n",
    "#products = [\"car tyres\",\"mobile phones\", \"motor bikes\"]\n",
    "\n",
    "#for product in products:\n",
    "    \n",
    "    #output=chain.run(product).strip()\n",
    "    #print(f\"product name '{product}'\")\n",
    "    #print(f\"{output}\\n\")\n",
    "    \n",
    "product = \"genrative AI\"\n",
    "output=chain.run(product).strip()\n",
    "print(f\"product name '{product}'\")\n",
    "print(f\"{output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product name 'system OS'\n",
      "1. Microsoft\n",
      "2. Apple\n",
      "3. Google\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product = \"system OS\"\n",
    "output=chain.run(product).strip()\n",
    "print(f\"product name '{product}'\")\n",
    "print(f\"{output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: genrative AI\n",
      "AI: \n",
      "\n",
      "1. OpenAI\n",
      "2. Google DeepMind\n",
      "3. IBM Watson\n",
      "Human: system OS\n",
      "AI: \n",
      "\n",
      "1. Microsoft\n",
      "2. Apple\n",
      "3. Google \n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product name 'genrative AI'\n",
      "1. OpenAI\n",
      "2. DeepMind\n",
      "3. NNAISENSE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationEntityMemory\n",
    "\n",
    "memory=ConversationEntityMemory(llm=llm,k=2)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"what is top 3 compines that make {product}, just give company name in list\")\n",
    "\n",
    "chain = LLMChain(llm=llm,prompt=prompt,memory=memory)\n",
    "\n",
    "#products = [\"car tyres\",\"mobile phones\", \"motor bikes\"]\n",
    "\n",
    "#for product in products:\n",
    "    \n",
    "    #output=chain.run(product).strip()\n",
    "    #print(f\"product name '{product}'\")\n",
    "    #print(f\"{output}\\n\")\n",
    "    \n",
    "product = \"genrative AI\"\n",
    "output=chain.run(product).strip()\n",
    "print(f\"product name '{product}'\")\n",
    "print(f\"{output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product name 'mobile OS'\n",
      "1. Google (Android)\n",
      "2. Apple (iOS)\n",
      "3. Huawei (HarmonyOS)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product = \"mobile OS\"\n",
    "output=chain.run(product).strip()\n",
    "print(f\"product name '{product}'\")\n",
    "print(f\"{output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product name 'SAAS products'\n",
      "1. Salesforce\n",
      "2. Microsoft\n",
      "3. Adobe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product = \"SAAS products\"\n",
    "output=chain.run(product).strip()\n",
    "print(f\"product name '{product}'\")\n",
    "print(f\"{output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: genrative AI\n",
      "AI: \n",
      "\n",
      "1. OpenAI\n",
      "2. DeepMind\n",
      "3. NNAISENSE\n",
      "Human: mobile OS\n",
      "AI: \n",
      "\n",
      "1. Google (Android)\n",
      "2. Apple (iOS)\n",
      "3. Huawei (HarmonyOS)\n",
      "Human: SAAS products\n",
      "AI: \n",
      "\n",
      "1. Salesforce\n",
      "2. Microsoft\n",
      "3. Adobe \n"
     ]
    }
   ],
   "source": [
    "for i, msg in enumerate(chain.memory.buffer):\n",
    "    if i % 2 == 0:\n",
    "        print(f\"Human: {msg.content}\")\n",
    "    else:\n",
    "        print(f\"AI: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
